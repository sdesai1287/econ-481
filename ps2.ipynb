{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 0: \n",
    "\n",
    "Please write a function that takes no arguments and returns a link to your solutions on GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://github.com/sdesai1287/econ-481/blob/main/ps2.py'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def github() -> str:\n",
    "    \"\"\"\n",
    "    arguments: none\n",
    "    returns: a link to your solutions on GitHub.\n",
    "    \"\"\"\n",
    "\n",
    "    return \"https://github.com/sdesai1287/econ-481/blob/main/ps2.py\"\n",
    "github()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1: \n",
    "\n",
    "Please write a function that returns 1000 simulated observations via the following data generating process:\n",
    "\n",
    "\n",
    "In particular, your function should take one argument, seed, an integer that is used to set a seed (this should default to 481 if not provided), and should return a tuple of two elements, (y,X) where y is a (1000, 1) np.array and X is a (1000, 3) np.array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 1), (1000, 3))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def simulate_data(seed: int = 481) -> tuple:\n",
    "    \"\"\"\n",
    "    arguments: an integer seed\n",
    "    returns: 1000 simulated observations in the form of a (y, X) tuple\n",
    "    where where y is a (1000, 1) np.array and X is a (1000, 3) np.array \n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "        \n",
    "    X = np.random.normal(loc= 0, scale= np.sqrt(2), size=(1000, 3))\n",
    "    e = np.random.normal(loc= 0, scale= 1, size=(1000, 1))\n",
    "    y = 5 + 3 * X[:, 0] + 2 * X[:, 1] + 6 * X[:, 2] + e[:, 0]\n",
    "    y = y.reshape((-1, 1))\n",
    "    return (y, X)\n",
    "\n",
    "y, X = simulate_data()\n",
    "y.shape, X.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2: \n",
    "\n",
    "Write a function that estimates the MLE parameters for data simulated as above\n",
    "\n",
    "In particular, your function should take as arguments a (1000, 1) np.array y and a (1000, 3) np.array X and return a (4, 1) np.array with the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.97700026],\n",
       "       [3.00195208],\n",
       "       [2.05045067],\n",
       "       [5.98400365]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "N, d = X.shape\n",
    "\n",
    "def log_likelihood(parameters, y, X) :\n",
    "    \"\"\"\n",
    "    arguments: parameters, y and X to do log likelihood estimation on\n",
    "    returns: the log likelihood function to minimize\n",
    "    \"\"\"\n",
    "    parameters = np.array(parameters).reshape((-1, 1))\n",
    "\n",
    "    X_with_intercept = np.hstack((np.ones((N, 1)), X))\n",
    "    \n",
    "    # Calculate predicted values\n",
    "    y_pred = np.matmul(X_with_intercept, parameters)\n",
    "    residuals = y - y_pred\n",
    "    ll = -(N * 0.5 * (np.log(2 * np.pi)) + 0.5 * np.sum(residuals**2))\n",
    "    return -ll\n",
    "\n",
    "def estimate_mle(y: np.array, X: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    arguments: data y and X representing observations\n",
    "    returns: MLE estimates of the parameters\n",
    "    \"\"\"\n",
    "    parameters = [0] * (d + 1)\n",
    "    result = minimize(log_likelihood, x0 = parameters, args=(y, X), method= 'Nelder-Mead')   \n",
    "    return result.x.reshape((-1, 1))\n",
    "    \n",
    "estimate_mle(y, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 3: \n",
    "\n",
    "Write a function to estimate the OLS coefficients for the simulated data, with a catch: do not use the closed-form solution\n",
    "\n",
    "In particular, your function should take as arguments a (1000, 1) np.array y and a (1000, 3) np.array X and return a (4, 1) np.array with the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.97696955],\n",
       "       [3.00201259],\n",
       "       [2.05039983],\n",
       "       [5.98397027]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def sum_of_squared_residuals(parameters, y, X) :\n",
    "    \"\"\"\n",
    "    arguments: parameters, y and X to do OLS estimation on\n",
    "    returns: the sum of squared residuals to minimize \n",
    "    \"\"\"\n",
    "    parameters = np.array(parameters, dtype=np.float64).reshape((-1, 1))\n",
    "    X = np.hstack((np.ones((N, 1)), X))\n",
    "    \n",
    "    # Calculate predicted values\n",
    "    y_pred = np.matmul(X, parameters)\n",
    "\n",
    "    # Calculate error term (residuals)\n",
    "    residuals = y - y_pred\n",
    "\n",
    "    # Calculate and return the sum of residuals\n",
    "    ssr = np.sum(residuals ** 2)\n",
    "    return ssr\n",
    "\n",
    "def estimate_ols(y: np.array, X: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    arguments: data y and X representing observations\n",
    "    returns: OLS estimates of the parameters\n",
    "    \"\"\"\n",
    "    parameters = [0] * (d + 1)\n",
    "    result = minimize(sum_of_squared_residuals, x0 = parameters, args=(y, X))\n",
    "    return result.x.reshape((-1, 1))\n",
    "    \n",
    "estimate_ols(y, X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
